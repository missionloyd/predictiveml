{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This first script is too slow (takes more than 8 hours to complete 1 dataset). Speed improvements are made in the next script.\n",
    "# Build CSV file from ../clean_data/*.csv\n",
    "\n",
    "# Import dependencies\n",
    "import pandas as pd\n",
    "#pd.options.display.width = 0\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "import numpy as np\n",
    "from timezonefinder import TimezoneFinder\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.std import tqdm\n",
    "\n",
    "from get_weather_data_at_location_and_hour import *\n",
    "\n",
    "# Import CSV file\n",
    "file = \"../clean_data/Stadium_Data.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# print(df.head())\n",
    "# print(len(df))\n",
    "\n",
    "tf = TimezoneFinder()\n",
    "\n",
    "df_extended = pd.DataFrame()\n",
    "\n",
    "for index, row in tqdm( df.iterrows(), total=len(df) ):\n",
    "    #print(f\"Row {index}: {row['ts']}, {row['latitude']}, {row['longitude']}\")\n",
    "\n",
    "    # Convert timestamp to local time\n",
    "    dt_local = datetime.strptime(row['ts'], '%Y-%m-%dT%H:%M:%S')\n",
    "    local_time_str = dt_local.strftime('%Y-%m-%dT%H:%M')\n",
    "\n",
    "    # Figure out local time zone\n",
    "    local_time_zone_str = tf.timezone_at(lng=row['longitude'], lat=row['latitude'])\n",
    "    utc_time_str, timezone_diff_hrs = local_time_to_utc_str(local_time_str, local_time_zone_str)\n",
    "\n",
    "    # Get the elevation at the given latitude and longitude\n",
    "    elevation_meters = get_elevation_online(row['latitude'], row['longitude'])\n",
    "\n",
    "    # Get weather data\n",
    "    get_24hour_data = False # Get weather data for the specified local hour\n",
    "    weather_data_dict = get_weather_data_at_location_and_hour(row['latitude'], row['longitude'], elevation_meters, utc_time_str, timezone_diff_hrs, get_24hour_data)\n",
    "\n",
    "    # Convert the weather_data_dict to a pandas Series object\n",
    "    weather_data_series = pd.Series(weather_data_dict)\n",
    "\n",
    "    # Append the weather_data_series to the original row\n",
    "    combined_series = pd.concat([row, weather_data_series], axis=0)\n",
    "\n",
    "    # Append the combined_row to the new DataFrame\n",
    "    df_extended = pd.concat([df_extended, combined_series.to_frame().T], axis=0) # to_frame().T converts the Series to a DataFrame row\n",
    "\n",
    "df_extended.columns = df_extended.columns.str.lower()\n",
    "print(df_extended)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_extended.to_csv(\"../clean_data_extended/Stadium_Data_Extended.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This second script makes significant speed improvements (>10x) for the online query, by pulling query in 24-hour chunks.\n",
    "# Build CSV file from ../clean_data/*.csv\n",
    "\n",
    "# Import dependencies\n",
    "import pandas as pd\n",
    "#pd.options.display.width = 0\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "import numpy as np\n",
    "from timezonefinder import TimezoneFinder\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.std import tqdm\n",
    "\n",
    "from get_weather_data_at_location_and_hour import *\n",
    "\n",
    "# csv_name = 'Stadium_Data'\n",
    "csv_name = 'Science_Initiative_Building_Data'\n",
    "\n",
    "# Import CSV file\n",
    "file = f'../clean_data/{csv_name}.csv'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# print(df.head())\n",
    "# print(len(df))\n",
    "\n",
    "tf = TimezoneFinder()\n",
    "\n",
    "df_extended = pd.DataFrame()\n",
    "\n",
    "running_chunk = False\n",
    "row_counter = 0\n",
    "get_elevation = True # Only get the elevation once per file (to improve speed)\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # Convert timestamp to local time\n",
    "    dt_local = datetime.strptime(row['ts'], '%Y-%m-%dT%H:%M:%S')\n",
    "    local_time_str = dt_local.strftime('%Y-%m-%dT%H:%M')\n",
    "\n",
    "    # Figure out local time zone\n",
    "    local_time_zone_str = tf.timezone_at(lng=row['longitude'], lat=row['latitude'])\n",
    "    utc_time_str, timezone_diff_hrs = local_time_to_utc_str(local_time_str, local_time_zone_str)\n",
    "\n",
    "    dt_utc = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M')\n",
    "\n",
    "    # Check if dt_utc is a new day, and if so, start a new 24-hour chunk\n",
    "    if dt_utc.hour == 0:\n",
    "        running_chunk = True\n",
    "        row_counter = 0\n",
    "\n",
    "        row_df_24 = pd.DataFrame()  # Initialize the DataFrame for the 24-hour chunk\n",
    "\n",
    "        # Get the elevation at the given latitude and longitude\n",
    "        if get_elevation:\n",
    "            elevation_meters = get_elevation_online(row['latitude'], row['longitude'])\n",
    "            get_elevation = False\n",
    "\n",
    "        # Get weather data in 24-hour chunks\n",
    "        get_24hour_data = True  # Get weather data for the entire UTC 24-hour day\n",
    "        weather_data_dict_24 = get_weather_data_at_location_and_hour(row['latitude'], row['longitude'], elevation_meters, utc_time_str, timezone_diff_hrs, get_24hour_data)\n",
    "\n",
    "        # Convert the weather_data_dict to a pandas DataFrame object\n",
    "        weather_data_df_24 = pd.DataFrame(weather_data_dict_24)\n",
    "\n",
    "    # Run this row by row until the 24-hour chunk is complete\n",
    "    if running_chunk:\n",
    "        row_counter += 1\n",
    "\n",
    "        # Assemble rows for the 24-hour chunk\n",
    "        row_df_24 = pd.concat([row_df_24, row.to_frame().T], axis=0)  # to_frame().T converts the Series to a DataFrame row\n",
    "\n",
    "    # Once the 24-hour chunk is complete, append it to the new DataFrame\n",
    "    if row_counter == 24:\n",
    "        running_chunk = False\n",
    "        row_counter = 0\n",
    "        \n",
    "        weather_data_df_24.index = row_df_24.index\n",
    "        row_df_24 = pd.concat([row_df_24, weather_data_df_24], axis=1)\n",
    "\n",
    "        # Append the combined_row to the new DataFrame\n",
    "        df_extended = pd.concat([df_extended, row_df_24], axis=0)\n",
    "    elif not running_chunk:\n",
    "        # Get the elevation at the given latitude and longitude\n",
    "        if get_elevation:\n",
    "            elevation_meters = get_elevation_online(row['latitude'], row['longitude'])\n",
    "            get_elevation = False\n",
    "\n",
    "        # Get weather data\n",
    "        get_24hour_data = False  # Get weather data for the specified local hour\n",
    "        weather_data_dict = get_weather_data_at_location_and_hour(row['latitude'], row['longitude'], elevation_meters, utc_time_str, timezone_diff_hrs, get_24hour_data)\n",
    "\n",
    "        # Convert the weather_data_dict to a pandas Series object\n",
    "        weather_data_series = pd.Series(weather_data_dict)\n",
    "\n",
    "        # Append the weather_data_series to the original row\n",
    "        combined_series = pd.concat([row, weather_data_series], axis=0)\n",
    "\n",
    "        # Append the combined_row to the new DataFrame\n",
    "        df_extended = pd.concat([df_extended, combined_series.to_frame().T], axis=0)  # to_frame().T converts the Series to a DataFrame row\n",
    "\n",
    "df_extended.columns = df_extended.columns.str.lower()\n",
    "#print(df_extended)\n",
    "\n",
    "df_extended = df_extended.drop(columns=['forecast', 'time_utc', 'time_local'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_extended.to_csv(f'../clean_data_extended/{csv_name}_Extended.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: -- Working on General_Storage_Data.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 547/29664 [00:33<16:23, 29.61it/s] "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "from build_extended_datafile import *\n",
    "\n",
    "#csv_name = 'Science_Initiative_Building_Data'\n",
    "#build_extended_datafile(csv_name)\n",
    "\n",
    "# Check folder 'clean_data' for *.csv files and create a list of the filenames\n",
    "csv_files_to_work = []\n",
    "for file_name in os.listdir('../clean_data'):\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Check if file is already present inside the 'clean_data_extended' folder\n",
    "        if not os.path.isfile(f'../clean_data_extended/{file_name}_Extended.csv'):\n",
    "            csv_files_to_work.append(file_name[:-4]) # Remove the '.csv' extension\n",
    "\n",
    "#print(csv_files_to_work)\n",
    "\n",
    "# Build the extended datafiles\n",
    "for csv_name in csv_files_to_work:\n",
    "    print(f':: -- Working on {csv_name}.csv ...')\n",
    "    build_extended_datafile(csv_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import CSV file\n",
    "#file = \"../clean_data_extended/Stadium_Data_Extended.csv\"\n",
    "#df_extended = pd.read_csv(file)\n",
    "\n",
    "#print(df_extended.tail(100))\n",
    "\n",
    "# Assuming your df_extended DataFrame is already created\n",
    "\n",
    "# Convert the 'ts' column to datetime objects\n",
    "df_extended['ts'] = pd.to_datetime(df_extended['ts'])\n",
    "\n",
    "# Calculate the time difference in hours since the first data point\n",
    "df_extended['hours_elapsed'] = (df_extended['ts'] - df_extended['ts'].iloc[0]).dt.total_seconds() / 3600\n",
    "\n",
    "# Create a plot with a specified size\n",
    "fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Plot the present_elec_kwh column with respect to the hours_elapsed column\n",
    "ax1.plot(df_extended['hours_elapsed'], df_extended['present_elec_kwh'], label='Elec (KWH)', color='#1f77b4', alpha=0.8)\n",
    "ax1.set_xlabel('Time (hours)')\n",
    "ax1.set_ylabel('Elec (KWH)')\n",
    "ax1.tick_params(axis='y', labelcolor='#1f77b4')\n",
    "\n",
    "# Create a twinx axis sharing the x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the temp_c column with respect to the hours_elapsed column\n",
    "ax2.plot(df_extended['hours_elapsed'], df_extended['temp_c'], label='Temp (C)', color='#ff7f0e', alpha=0.8)\n",
    "ax2.set_ylabel('Temp (C)')\n",
    "ax2.tick_params(axis='y', labelcolor='#ff7f0e')\n",
    "\n",
    "# Set the title for the plot\n",
    "plt.title('Elec (KWH) and Temp (C) vs Time (hours)')\n",
    "\n",
    "# Create a single legend for both lines\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "lines = lines1 + lines2\n",
    "labels = labels1 + labels2\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
