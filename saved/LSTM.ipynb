{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_list = ['Energy_Innovation_Center_Data.csv']\n",
    "\n",
    "in_path = './clean_data/'\n",
    "\n",
    "for building in buildings_list:\n",
    "    df = pd.read_csv(in_path + building)\n",
    "\n",
    "    # Convert the data into a Pandas dataframe\n",
    "    df[\"ts\"] = pd.to_datetime(df[\"ts\"])\n",
    "    df = df.drop_duplicates(subset=[\"bldgname\", \"ts\"])\n",
    "    df = df.sort_values([\"bldgname\", \"ts\"])\n",
    "\n",
    "    # Group the dataframe by building name and timestamp\n",
    "    groups = df.groupby(\"bldgname\")\n",
    "    df = df.set_index(\"ts\")\n",
    "\n",
    "    orig_cols = df.columns\n",
    "    y_columns = [\"present_elec_kwh\", \"present_htwt_mmbtu\", \"present_wtr_usgal\", \"present_chll_tonhr\", \"present_co2_tons\"]\n",
    "    header = [\"ts\"] + y_columns\n",
    "\n",
    "    # Train the LSTM models on the data\n",
    "    models = {}\n",
    "\n",
    "    print(building)\n",
    "    epochs = [5, 10, 15, 50, 100]\n",
    "\n",
    "    for name, group in groups:\n",
    "        bldgname = name\n",
    "\n",
    "        group = group.drop_duplicates(subset=[\"ts\"])\n",
    "        model_data = group[header]\n",
    "\n",
    "        for y in y_columns:\n",
    "            if model_data[y].count() >= 365*24 and y != 'present_co2_tons':\n",
    "                for epoch in epochs:\n",
    "                    model_data = model_data.rename(columns={ \"ts\": \"ds\", y: \"y\" })\n",
    "                    model_data = model_data.sort_values([\"ds\"])\n",
    "                    # model_data = model_data.dropna(subset=\"y\")\n",
    "\n",
    "                    # Interpolate missing values in 'y' column of model_data using linear method and fill values in both directions.\n",
    "                    model_data['y'] = model_data['y'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "                    # normalize the data\n",
    "                    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "                    data_scaled = scaler.fit_transform(model_data[\"y\"].values.reshape(-1, 1))\n",
    "\n",
    "                    # split the data into training and testing sets\n",
    "                    train_size = int(len(data_scaled) * 0.8)\n",
    "                    test_size = len(data_scaled) - train_size\n",
    "                    train_data = data_scaled[0:train_size,:]\n",
    "                    test_data = data_scaled[train_size:len(data_scaled),:]\n",
    "\n",
    "                    # define the window size\n",
    "                    window_size = 7\n",
    "\n",
    "                    # create the training data set\n",
    "                    def create_dataset(dataset, window_size):\n",
    "                        X, y = [], []\n",
    "                        for i in range(window_size, len(dataset)):\n",
    "                            X.append(dataset[i-window_size:i, 0])\n",
    "                            y.append(dataset[i, 0])\n",
    "                        X, y = np.array(X), np.array(y)\n",
    "                        return X, y\n",
    "\n",
    "                    X_train, y_train = create_dataset(train_data, window_size)\n",
    "\n",
    "                    # create the testing data set\n",
    "                    X_test, y_test = create_dataset(test_data, window_size)\n",
    "\n",
    "                    # reshape the input data to be 3-dimensional for LSTM model\n",
    "                    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "                    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]))\n",
    "\n",
    "                    # Create the LSTM model\n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "                    model.add(Dropout(0.2))\n",
    "                    model.add(LSTM(units=50, return_sequences=True))\n",
    "                    model.add(Dropout(0.2))\n",
    "                    model.add(LSTM(units=50))\n",
    "                    model.add(Dropout(0.2))\n",
    "                    model.add(Dense(units=1))\n",
    "                    \n",
    "                    # Compile the model (run_eagerly=False for prod)\n",
    "                    model.compile(optimizer='adam', loss='mean_squared_error', run_eagerly=True)\n",
    "\n",
    "                    # Create the EarlyStopping callback\n",
    "                    early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1, mode='min')\n",
    "\n",
    "                    # Train the model\n",
    "                    model.fit(X_train, y_train, epochs=epoch, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
    "\n",
    "                    # Save the model\n",
    "                    # model.save(par_folder + '/' + bldgname + '_' + y + '_LSTM_model.h5')\n",
    "\n",
    "                    # Predict on the test set\n",
    "                    predictions = model.predict(X_test)\n",
    "\n",
    "                    # Inverse transform the predictions and actual values\n",
    "                    predictions = scaler.inverse_transform(predictions)\n",
    "                    y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "                    y_train = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "                    # Slice the predicted values array to the desired prediction length\n",
    "                    prediction_length_hours = len(y_test) # set the prediction length to 24 hours\n",
    "                    predictions = predictions[-prediction_length_hours:]\n",
    "\n",
    "                    # Calculate the RMSE\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test[-prediction_length_hours:], predictions))\n",
    "                    # print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "                    models[(bldgname, y, rmse)] = (y_test, y_train, predictions, rmse, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual values and predictions\n",
    "for name, (y_test, y_train, predictions, rmse, epoch) in models.items():\n",
    "    bldgname, y, rmse = name\n",
    "    print(f'Root Mean Squared Error: {rmse}, Epoch: {epoch}')\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Get the length of the training data to correctly index the predictions\n",
    "    train_len = len(y_train)\n",
    "    \n",
    "    # Plot the actual values\n",
    "    # ax.plot(np.concatenate([y_train, y_test]), label='Actual Values')\n",
    "    ax.plot(y_test, label='Actual Values')\n",
    "    \n",
    "    # Plot the predictions at the correct indices\n",
    "    # ax.plot(range(train_len, train_len + len(y_test)), predictions, label='Predicted Values')\n",
    "    ax.plot(predictions, label='Predicted Values')\n",
    "\n",
    "    ax.set_title(bldgname + '_' + y + ' Consumption')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
